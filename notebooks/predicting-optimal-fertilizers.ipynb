{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91717,"databundleVersionId":12184666,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb # Using the much faster LightGBM model\nfrom sklearn.metrics import accuracy_score, classification_report\nimport joblib\nimport pickle\nimport os\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:51:33.013636Z","iopub.execute_input":"2025-06-22T12:51:33.013987Z","iopub.status.idle":"2025-06-22T12:51:33.020221Z","shell.execute_reply.started":"2025-06-22T12:51:33.013964Z","shell.execute_reply":"2025-06-22T12:51:33.019236Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Define File Paths for Kaggle","metadata":{}},{"cell_type":"code","source":"INPUT_DIR = \"/kaggle/input/playground-series-s5e6\"\nOUTPUT_DIR = \"/kaggle/working/\" # Kaggle's directory for saving files","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:51:33.021774Z","iopub.execute_input":"2025-06-22T12:51:33.022169Z","iopub.status.idle":"2025-06-22T12:51:33.05019Z","shell.execute_reply.started":"2025-06-22T12:51:33.022149Z","shell.execute_reply":"2025-06-22T12:51:33.0491Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Load Training Data","metadata":{}},{"cell_type":"code","source":"print(\"--- Loading Training Data ---\")\ntry:\n    train_df = pd.read_csv(os.path.join(INPUT_DIR, 'train.csv'))\n    print(\"train.csv loaded successfully.\")\nexcept FileNotFoundError:\n    print(f\"Error: 'train.csv' not found in {INPUT_DIR}.\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:51:33.051634Z","iopub.execute_input":"2025-06-22T12:51:33.051942Z","iopub.status.idle":"2025-06-22T12:51:33.763Z","shell.execute_reply.started":"2025-06-22T12:51:33.051921Z","shell.execute_reply":"2025-06-22T12:51:33.761547Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Training Data Feature Engineering and Preprocessing","metadata":{}},{"cell_type":"code","source":"print(\"--- Preprocessing Data ---\")\ny = train_df['Fertilizer Name']\nX = train_df.drop('Fertilizer Name', axis=1)\n\ncategorical_features = ['Soil Type', 'Crop Type']\nfor col in categorical_features:\n    X[col] = X[col].astype('category')\n\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:51:33.764555Z","iopub.execute_input":"2025-06-22T12:51:33.764912Z","iopub.status.idle":"2025-06-22T12:51:34.175204Z","shell.execute_reply.started":"2025-06-22T12:51:33.764883Z","shell.execute_reply":"2025-06-22T12:51:34.174363Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Model Training and Optimization","metadata":{}},{"cell_type":"code","source":"print(\"--- Training LightGBM with built-in categorical support ---\")\nbest_model = lgb.LGBMClassifier(random_state=42, n_estimators=150)\n\n# Pass the data directly. LightGBM will handle the 'category' dtype automatically.\nbest_model.fit(X, y_encoded)\n\nprint(\"Model training is complete.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:51:34.177185Z","iopub.execute_input":"2025-06-22T12:51:34.177439Z","iopub.status.idle":"2025-06-22T12:52:05.31915Z","shell.execute_reply.started":"2025-06-22T12:51:34.177422Z","shell.execute_reply":"2025-06-22T12:52:05.318195Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Save the Model and Supporting Files","metadata":{}},{"cell_type":"code","source":"print(\"--- Saving Model and Supporting Files ---\")\njoblib.dump(best_model, os.path.join(OUTPUT_DIR, 'fertilizer_lgbm_model.joblib'))\n# We save the feature names to ensure consistency in the prediction step\nwith open(os.path.join(OUTPUT_DIR, 'model_features.pkl'), 'wb') as f:\n    pickle.dump(list(X.columns), f)\nwith open(os.path.join(OUTPUT_DIR, 'label_encoder.pkl'), 'wb') as f:\n    pickle.dump(le, f)\n\nprint(\"\\nTraining complete. Model and supporting files have been saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:52:05.320146Z","iopub.execute_input":"2025-06-22T12:52:05.320404Z","iopub.status.idle":"2025-06-22T12:52:05.428503Z","shell.execute_reply.started":"2025-06-22T12:52:05.320385Z","shell.execute_reply":"2025-06-22T12:52:05.427493Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Load Test Data and Saved Files","metadata":{}},{"cell_type":"code","source":"print(\"--- Loading Test Data and Saved Model ---\")\ntry:\n    test_df = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\n    print(\"test.csv loaded successfully.\")\n\n    # --- DIAGNOSTIC STEP: Print all column names ---\n    print(\"\\nColumns found in test.csv:\")\n    print(list(test_df.columns))\n    print(\"--------------------------------------\\n\")\n    # ---------------------------------------------\n\n    # --- ACTION REQUIRED: Find your ID column in the list above ---\n    # Replace 'id' below with the correct name of your ID column from the printed list.\n    ID_COLUMN_NAME = 'id'\n    # -------------------------------------------------------------\n\n    test_ids = test_df[ID_COLUMN_NAME]\n    test_df_features = test_df.drop(ID_COLUMN_NAME, axis=1)\n\n    model = joblib.load(os.path.join(OUTPUT_DIR, 'fertilizer_lgbm_model.joblib'))\n    with open(os.path.join(OUTPUT_DIR, 'model_features.pkl'), 'rb') as f:\n        model_features = pickle.load(f)\n    with open(os.path.join(OUTPUT_DIR, 'label_encoder.pkl'), 'rb') as f:\n        le = pickle.load(f)\n\nexcept FileNotFoundError as e:\n    print(f\"Error: Could not find a required file. {e}\")\n    exit()\nexcept KeyError:\n    print(f\"KeyError: The column '{ID_COLUMN_NAME}' was not found in test.csv.\")\n    print(\"Please update the ID_COLUMN_NAME variable with the correct name from the list of columns printed above.\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:52:05.429585Z","iopub.execute_input":"2025-06-22T12:52:05.430307Z","iopub.status.idle":"2025-06-22T12:52:05.628906Z","shell.execute_reply.started":"2025-06-22T12:52:05.430269Z","shell.execute_reply":"2025-06-22T12:52:05.627982Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Preprocess Test Data","metadata":{}},{"cell_type":"code","source":"print(\"--- Preprocessing Test Data without One-Hot Encoding ---\")\n# KEY CHANGE: Apply the same 'category' conversion\ncategorical_features = ['Soil Type', 'Crop Type']\nfor col in categorical_features:\n    if col in test_df.columns:\n        test_df[col] = test_df[col].astype('category')\n\n# Ensure test columns match the order of the trained model\ntest_final = test_df[model_features]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:52:05.630173Z","iopub.execute_input":"2025-06-22T12:52:05.630532Z","iopub.status.idle":"2025-06-22T12:52:05.673915Z","shell.execute_reply.started":"2025-06-22T12:52:05.630507Z","shell.execute_reply":"2025-06-22T12:52:05.672867Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Make Predictions","metadata":{}},{"cell_type":"code","source":"print(\"--- Making Predictions ---\")\npredictions_encoded = model.predict(test_final)\nfinal_predictions = le.inverse_transform(predictions_encoded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:52:05.67517Z","iopub.execute_input":"2025-06-22T12:52:05.675462Z","iopub.status.idle":"2025-06-22T12:52:19.684019Z","shell.execute_reply.started":"2025-06-22T12:52:05.675442Z","shell.execute_reply":"2025-06-22T12:52:19.682913Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 9. Create Submission File","metadata":{}},{"cell_type":"code","source":"print(\"--- Creating Submission File ---\")\n# --- NEW: Create the DataFrame with the 'id' and the prediction ---\nsubmission_df = pd.DataFrame({\n    'id': test_ids,\n    'Fertilizer Name': final_predictions\n})\n# --------------------------------------------------------------\n\nsubmission_df.to_csv(os.path.join(OUTPUT_DIR, 'submission.csv'), index=False)\n\nprint(\"\\nPrediction complete!\")\nprint(\"The predictions have been saved to 'submission.csv'.\")\nprint(\"\\nFirst 5 rows of the submission file:\")\nprint(submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T12:52:19.685059Z","iopub.execute_input":"2025-06-22T12:52:19.685361Z","iopub.status.idle":"2025-06-22T12:52:19.941702Z","shell.execute_reply.started":"2025-06-22T12:52:19.685329Z","shell.execute_reply":"2025-06-22T12:52:19.940795Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}