{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12236665,"sourceType":"datasetVersion","datasetId":7710064}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. IMPORTING IMPORTANT LIBRARIES AND LOADING THE DATA","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T14:13:06.789049Z","iopub.execute_input":"2025-06-26T14:13:06.789719Z","iopub.status.idle":"2025-06-26T14:13:06.79434Z","shell.execute_reply.started":"2025-06-26T14:13:06.789694Z","shell.execute_reply":"2025-06-26T14:13:06.793464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv('/kaggle/input/industrial-residential-air-quality-classification/City_Types.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:52:12.953444Z","iopub.execute_input":"2025-06-26T13:52:12.953833Z","iopub.status.idle":"2025-06-26T13:52:13.064621Z","shell.execute_reply.started":"2025-06-26T13:52:12.95381Z","shell.execute_reply":"2025-06-26T13:52:13.063679Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2.DATA CLEANING AND PREPARATION","metadata":{}},{"cell_type":"code","source":"# Convert 'Date' column to datetime objects\ndf['Date'] = pd.to_datetime(df['Date'])\n\n# Check for missing values\nprint(\"Missing values in each column:\\n\", df.isnull().sum())\n\n# Check for duplicate rows\nprint(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n# Remove duplicates if any\ndf.drop_duplicates(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:52:45.14884Z","iopub.execute_input":"2025-06-26T13:52:45.149556Z","iopub.status.idle":"2025-06-26T13:52:45.255398Z","shell.execute_reply.started":"2025-06-26T13:52:45.14953Z","shell.execute_reply":"2025-06-26T13:52:45.254409Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3.DESCRIPTIVE STATISTICS","metadata":{}},{"cell_type":"code","source":"# Summary statistics for all pollutants\nprint(\"\\nSummary statistics for all pollutants:\")\nprint(df.describe())\n\n# Summary statistics grouped by 'Type'\nprint(\"\\nSummary statistics grouped by City Type:\")\nprint(df.groupby('Type').describe())\n\n# Summary statistics grouped by 'City'\nprint(\"\\nSummary statistics grouped by City:\")\nprint(df.groupby('City').describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T13:53:57.150241Z","iopub.execute_input":"2025-06-26T13:53:57.150539Z","iopub.status.idle":"2025-06-26T13:53:57.298747Z","shell.execute_reply.started":"2025-06-26T13:53:57.150519Z","shell.execute_reply":"2025-06-26T13:53:57.297839Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. EXPLORATORY DATA ANALYSIS","metadata":{}},{"cell_type":"code","source":"# Set the style for plots\nsns.set_style(\"whitegrid\")\n\n# a. Univariate Analysis (Distribution of each pollutant)\npollutants = ['CO', 'NO2', 'SO2', 'O3', 'PM2.5', 'PM10']\nplt.figure(figsize=(15, 10))\nfor i, pollutant in enumerate(pollutants, 1):\n    plt.subplot(2, 3, i)\n    sns.histplot(df[pollutant], kde=True)\n    plt.title(f'Distribution of {pollutant}')\nplt.tight_layout()\nplt.show()\n\n# b. Bivariate Analysis (Pollutant levels by City Type)\nplt.figure(figsize=(15, 10))\nfor i, pollutant in enumerate(pollutants, 1):\n    plt.subplot(2, 3, i)\n    sns.boxplot(x='Type', y=pollutant, data=df)\n    plt.title(f'{pollutant} Levels by City Type')\nplt.tight_layout()\nplt.show()\n\n# c. Correlation Analysis\nplt.figure(figsize=(10, 8))\ncorrelation_matrix = df[pollutants].corr()\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Correlation Matrix of Pollutants')\nplt.show()\n\n# d. Time-Series Analysis (Corrected)\n\n# 1. Define the numeric columns you want to analyze\npollutants = ['CO', 'NO2', 'SO2', 'O3', 'PM2.5', 'PM10']\n\n# 2. Set 'Date' as the index and select ONLY the numeric pollutant columns\n# This step is crucial to avoid the TypeError\ndf_numeric = df.set_index('Date')[pollutants]\n\n# 3. Resample and get the mean from your numeric-only data\n# This is the corrected line. Note that it uses 'df_numeric'.\ndf_daily = df_numeric.resample('D').mean()\n\n# 4. Plot the results, which will now work without error\nprint(\"Plotting daily average pollutant levels...\")\nplt.figure(figsize=(15, 12))\nfor i, pollutant in enumerate(pollutants, 1):\n    plt.subplot(3, 2, i)\n    df_daily[pollutant].plot(ax=plt.gca())\n    plt.title(f'Daily Average {pollutant} Levels Over Time')\n    plt.xlabel('Date')\n    plt.ylabel(pollutant)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T14:09:23.656709Z","iopub.execute_input":"2025-06-26T14:09:23.657031Z","iopub.status.idle":"2025-06-26T14:09:34.259428Z","shell.execute_reply.started":"2025-06-26T14:09:23.657007Z","shell.execute_reply":"2025-06-26T14:09:34.258508Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Summary of Performed Analysis\nI've analyzed the dataset, starting with data cleaning and preparation, followed by a detailed EDA. Here's what I found:\n\n1. Data Cleaning and Preparation:\n\n* The Date column has been converted to a proper datetime format to enable time-series analysis.\n\n* The dataset is clean, with no missing values or duplicate rows.\n\n2. Key Insights from Exploratory Data Analysis:\n\n**Here are the key takeaways from the visualizations:**\n\n* The distributions of all pollutants are right-skewed, indicating that there are instances of very high pollution levels (outliers) compared to the average. This is common in environmental data.\n\n**Pollutant Levels by City Type:**\n\n* As expected, 'Industrial' cities show significantly higher median levels and a wider range of all pollutants, especially CO, SO2, PM2.5, and PM10, compared to 'Residential' cities.\n\n* The difference is most pronounced for CO and SO2.\n\n**Correlation Between Pollutants:**\n\n* There is a strong positive correlation between PM2.5 and PM10, which makes sense as they are both particulate matter of different sizes.\n\n* CO, NO2, and SO2 also show moderate to strong positive correlations with each other and with particulate matter, suggesting they may originate from similar sources (e.g., industrial activities, traffic).\n\n* O3 (Ozone) shows a weak or even slightly negative correlation with some of the other pollutants. This is also expected, as ground-level ozone formation is a complex photochemical process that can be inversely related to high concentrations of other pollutants like NO2.\n\n**Time-Series Trends:**\n\n* The time-series plots reveal some fluctuations in pollutant levels over the year. A more in-depth analysis could uncover seasonal patterns. For instance, in many regions, particulate matter and CO levels tend to be higher in colder months.","metadata":{}},{"cell_type":"markdown","source":"# 4. BUILDING A MACHINE LEARNING MODEL  ","metadata":{}},{"cell_type":"code","source":"# --- A. Feature Engineering ---\ndf['Month'] = df['Date'].dt.month\ndf['DayOfWeek'] = df['Date'].dt.dayofweek\ndf['Hour'] = df['Date'].dt.hour\n\n# --- B. Data Preparation for Modeling ---\n\n# Define features (X) and target (y)\nfeatures = ['CO', 'NO2', 'SO2', 'O3', 'PM2.5', 'PM10', 'Month', 'DayOfWeek', 'Hour']\ntarget = 'Type'\n\nX = df[features]\ny = df[target]\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n# Scale numerical features\n# Note: We fit the scaler on the training data and transform both training and testing data\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# --- C. Model Training and Evaluation ---\n\n# a. Logistic Regression\nprint(\"--- Logistic Regression Model ---\")\nlog_reg = LogisticRegression(random_state=42)\nlog_reg.fit(X_train_scaled, y_train)\ny_pred_log_reg = log_reg.predict(X_test_scaled)\n\n# Evaluation\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_log_reg))\n\n# Confusion Matrix\ncm_log_reg = confusion_matrix(y_test, y_pred_log_reg)\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm_log_reg, annot=True, fmt='d', cmap='Blues', xticklabels=['Industrial', 'Residential'], yticklabels=['Industrial', 'Residential'])\nplt.title('Logistic Regression Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n# b. Random Forest Classifier\nprint(\"\\n--- Random Forest Classifier Model ---\")\nrand_forest = RandomForestClassifier(random_state=42, n_estimators=100)\nrand_forest.fit(X_train_scaled, y_train)\ny_pred_rand_forest = rand_forest.predict(X_test_scaled)\n\n# Evaluation\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_rand_forest))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rand_forest))\n\n# Confusion Matrix\ncm_rand_forest = confusion_matrix(y_test, y_pred_rand_forest)\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm_rand_forest, annot=True, fmt='d', cmap='Greens', xticklabels=['Industrial', 'Residential'], yticklabels=['Industrial', 'Residential'])\nplt.title('Random Forest Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n# c. Feature Importance from Random Forest\nfeature_importances = pd.DataFrame({'feature': features, 'importance': rand_forest.feature_importances_})\nfeature_importances = feature_importances.sort_values('importance', ascending=False)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x='importance', y='feature', data=feature_importances)\nplt.title('Feature Importances from Random Forest')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T14:14:32.9596Z","iopub.execute_input":"2025-06-26T14:14:32.959919Z","iopub.status.idle":"2025-06-26T14:14:39.646604Z","shell.execute_reply.started":"2025-06-26T14:14:32.959896Z","shell.execute_reply":"2025-06-26T14:14:39.64569Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Machine Learning Model Summary\n* I built two different classification models: Logistic Regression and a Random Forest Classifier. Both were trained to predict whether a city is 'Industrial' or 'Residential' using the air quality and time-based features.\n\n1. Logistic Regression Model:\n\n**Accuracy: 97.4%**\n\n* This model performs very well, correctly classifying the city type over 97% of the time. The confusion matrix shows that it makes very few errors. For a simple and interpretable model, this is an excellent result.\n\n2. Random Forest Classifier Model:\n\n**Accuracy: 99.4%**\n\n* The Random Forest model is even more accurate, achieving an impressive 99.4% accuracy. This is a very strong indicator that the air quality data is a powerful predictor of the city type.\n\n* The confusion matrix for this model confirms its high performance, with even fewer misclassifications than the Logistic Regression model.\n\n**What Drives the Predictions? Feature Importance**\n* To understand which factors are most important for distinguishing between 'Industrial' and 'Residential' cities, I analyzed the feature importances from the Random Forest model.\n\n* The most important features are CO (Carbon Monoxide), SO2 (Sulfur Dioxide), and PM2.5. This aligns perfectly with our earlier EDA, which showed that these pollutants were significantly higher in industrial areas.\n\n* Other pollutants like NO2 and PM10 also contribute significantly.\n\n* The time-based features (Hour, Month, DayOfWeek) have less importance, but they still play a role in the model's predictions.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}